# Task: Research GitHub Spec-Kit for Task Specifications

## Metadata

| Field       | Value                                                  |
| ----------- | ------------------------------------------------------ |
| ID          | `005-003-research-spec-kit-task-specs`                 |
| Status      | `todo`                                                 |
| Priority    | `005` Research                                         |
| Created     | `2026-02-10 20:00`                                     |
| Started     |                                                        |
| Completed   |                                                        |
| Blocked By  |                                                        |
| Blocks      |                                                        |
| Assigned To |                                                        |
| Assigned At |                                                        |

---

## Context

Doyaken uses markdown task files with metadata tables and acceptance criteria. GitHub's spec-kit is purpose-built for generating structured specs that AI agents can execute against.

## Objective

Research spec-kit to understand its spec format, generation workflow, and how it bridges human intent to agent-executable tasks. Compare against doyaken's task file format.

## Sources

- https://github.com/github/spec-kit

## Research Questions

1. What is the spec format structure? How does it compare to doyaken's task markdown?
2. How does it generate specs from issues/PRs?
3. What metadata does it include for agent consumption?
4. How does it handle acceptance criteria and verification?
5. Does it support task decomposition or dependency chains?
6. What tooling exists for spec validation?

## Output

A list of concrete suggestions for improving doyaken's task file format, spec generation (EXPAND phase), and task decomposition, formatted as potential task descriptions.
